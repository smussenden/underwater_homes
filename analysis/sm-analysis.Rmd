---
title: "Underwater Homes Analysis"
author: "TBD"
date: "10/16/2019"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, paged.print=TRUE)
```
## Load Packages


```{r}

options(scipen=9999)
library(tidyverse)
library(janitor)
library(lubridate)
library(readxl)
library(zipcode)
library(maps)
library(tidycensus)
library(mapview)
library(corrr)

```

#READ THIS: 
#http://haasinstitute.berkeley.edu/sites/default/files/haasinsitute_underwateramerica_publish_0.pdf

## Load and Clean County Data

```{r}

# Load and clean new Core Logic data, by county

underwater_county <- read_xlsx("../data/input_data/negative_equity_share_county.xlsx")

# Clean data

underwater_county<- underwater_county %>%
  mutate(year=str_sub(yyyymm, 1,4)) %>%
  mutate(month=str_sub(yyyymm,5,6)) %>%
  select(state_code, fips_code, state_name, county_name,year, month, yyyymm, percent_negative_equity) %>%
  mutate(fips_code = as.character(fips_code)) %>%
  mutate(fips_code = case_when(str_length(fips_code) < 5  ~ paste0("0",fips_code),
                                TRUE ~ fips_code)
         )

# Create annual averages

underwater_county_year <- underwater_county %>%
  group_by(state_code, fips_code, state_name, county_name, year) %>%
  summarise(percent_negative_equity = mean(percent_negative_equity)) %>%
  mutate(percent_negative_equity = round(percent_negative_equity*100, 2)) %>%
  spread(year, percent_negative_equity) %>%
  rename_at(vars(matches("20")), funs(paste0("y", .)))

  
```

# Load and Clean Census Data

``` {r}
# Census Data
# Load ZCTA geography data 
acs_variable <- load_variables(2017, "acs5", cache = TRUE)

# Define census api key
census_api_key("549950d36c22ff16455fe196bbbd01d63cfbe6cf")

# Get pct_white, poverty, income data

acs_county_white <- get_acs(geography = "county", variables = c("B02001_002"), geometry = FALSE, survey="acs5", year = 2017, summary_var ="B01001_001") %>%
  mutate(pct_white = estimate/summary_est) %>%
  select(GEOID,NAME,pct_white) %>%
  clean_names()

acs_county_poverty <- get_acs(geography = "county", variables = c("B06012_002"), geometry = FALSE, survey="acs5", year = 2017, summary_var ="B01001_001") %>%
  mutate(pct_poverty = estimate/summary_est) %>%
  select(GEOID,NAME,pct_poverty) %>%
  clean_names()

acs_county_income <- get_acs(geography = "county", variables = c("B19013_001"), geometry = FALSE, survey="acs5", year = 2017) %>%
  select(GEOID,NAME, median_household_income = estimate) %>%
  clean_names()

acs_data <- acs_county_white %>%
  inner_join(acs_county_poverty) %>%
  inner_join(acs_county_income)

```

# Join ACS Data to Underwater Data

```{r}

underwater_county_year_join <- underwater_county_year %>%
  left_join(acs_data, by=c("fips_code" = "geoid")) %>%
  ungroup()

```

# Analysis

```{r}

years <- c("y2018","y2017","y2016","y2015","y2014","y2013","y2012","y2011","y2010","y2009")

for (year in years) {

corr_table <- underwater_county_year_join %>%
  select(-matches("code|state|name")) %>%
  select(year, matches("pct|median")) %>%
  filter(!is.na(deparse(substitute(year)))) %>%
  correlate() %>%
  select(rowname, year)

print(corr_table)
}  



```

## Zip Code Data
CoreLogic data. Percent of homes with negative equity for all U.S. ZipCodes. Think data is Q1 2019, but not sure. 
```{r0}
# Load and clean data by fixing zip codes to add a leading zero for northeastern zip codes
underwater <- read_xlsx("../data/input_data/corelogic_underwater_homes.xlsx") %>%
  clean_names() %>%
  mutate(zip_code = clean.zipcodes(zip_code)) %>%
  mutate(pct_homes_negative_equity = round(share_of_homes_in_negative_equity*100, 2)) %>%
  select(-share_of_homes_in_negative_equity)

write_csv(underwater, "../data/output_data/underwater_cleaned_z.csv")

# Check for dup zip codes 

underwater %>%
  group_by(zip_code) %>%
  summarise(count = n()) %>%
  arrange(desc(count))

# Load ZCTA geography data 
acs_variable <- load_variables(2017, "acs5", cache = TRUE)

# Define census api key
census_api_key("549950d36c22ff16455fe196bbbd01d63cfbe6cf")

# Get zip code geography data with total population zcta 2017
acs_zcta_total_pop <- get_acs(geography = "county", variables = c("B06012_001"), geometry = TRUE, survey="acs5", year = 2017)

# Join it
zcta_underwater_geography <- acs_zcta_total_pop %>%
  inner_join(underwater, by = c("GEOID" = "zip_code"))

# anti join

zcta_anti <- underwater %>%
  anti_join(acs_zcta_total_pop, by = c("zip_code" = "GEOID"))

zcta_anti_x <- acs_zcta_total_pop %>%
  anti_join(underwater, by = c("GEOID" = "zip_code"), keepall=TRUE)

```

```{r}
# make a map

#zcta_underwater_geography_x <- zcta_underwater_geography %>%
#  filter(share_of_homes_in_negative_equity > .05)

zcta_underwater_geography_x <- zcta_underwater_geography %>%
  filter(state_name == "New Jersey")


mapview(zcta_underwater_geography_x, zcol = "share_of_homes_in_negative_equity", legend = TRUE)
```



## Test Correlations

```{r}
# Get zip code geography data with total population zcta 2017
#acs_zcta_total_pop <- get_acs(geography = "zcta", variables = c("B06012_001"), geometry = TRUE, survey="acs5", year = 2017)

# Poverty B06012_002	Estimate!!Total!!Below 100 percent of the poverty level
acs_zcta_total_pov <- get_acs(geography = "zcta", variables = c("B06012_002"), geometry = TRUE, survey="acs5", year = 2017, summary_var = "B06012_001")

# Calculate MOE
acs_zcta_total_pov_x <- acs_zcta_total_pov %>%
  mutate(moe_percent = moe/estimate) %>%
  filter(moe_percent != "Inf") %>%
  filter(moe_percent < .2)

acs_zcta_total_pov_x <- acs_zcta_total_pov_x %>%
  left_join(underwater, by = c("GEOID" = "zip_code")) %>%
  mutate(pov_rate = estimate/summary_est)

  

```

## Examine the Data

High concentrations of negative equity in Connecticut, New Jersey and Maryland.

```{r}

underwater %>%
  filter(!is.na(share_of_homes_in_negative_equity)) %>%
  group_by(state_name) %>%
  summarise(mean_pct_underwater = mean(share_of_homes_in_negative_equity)*100) %>%
  arrange(desc(mean_pct_underwater))

```



```{r}
# County level analysis

underwater_x <- underwater %>%
  left_join(zip_county_crosswalk, by=c("zip_code" = "zip")) %>%
  group_by(zip_code) %>%
  summarise(count=n()) %>%
  arrange(desc(count)) %>%
  filter(count > 1)

# Build tables of share of homes in negative equity


underwater_counties <- underwater %>%
  filter(!is.na(share_of_homes_in_negative_equity)) %>%
  group_by(state_name, county_name) %>%
  summarise(mean_pct_underwater = mean(share_of_homes_in_negative_equity)*100) %>%
  arrange(desc(mean_pct_underwater)) %>%
  mutate(NAME = paste0())

# Get Census Data by County
census_api_key("549950d36c22ff16455fe196bbbd01d63cfbe6cf")

acs_county_total_pop <- get_acs(geography = "county", variables = c("B06012_001"), geometry = FALSE)


```

```{r}

# Define census api key
census_api_key("549950d36c22ff16455fe196bbbd01d63cfbe6cf")

# Examine ACS Variables
acs_variable <- load_variables(2017, "acs5", cache = TRUE)
# B07001 GEOGRAPHICAL MOBILITY IN THE PAST YEAR
  # Mobility B07001_017	Estimate!!Total!!Same house 1 year ago
#  B06012_002	 POVERTY STATUS IN THE PAST 12 MONTHS
  # Total Population B06012_001	Estimate!!Total
  # Poverty B06012_002	Estimate!!Total!!Below 100 percent of the poverty level
  # Poverty B06012_003	Estimate!!Total!!100 to 149 percent of the poverty level
  # Poverty B06012_004	Estimate!!Total!!At or above 150 percent of the poverty level

census_api_key("549950d36c22ff16455fe196bbbd01d63cfbe6cf")

acs_county_total_pop <- get_acs(geography = "county", variables = c("B06012_001"), geometry = FALSE)



acs_zip <- get_acs(geography = "zcta", variables = c("B06012_001"), geometry = FALSE)


acs <- acs %>%
  left_join(acs_variable, by = c("variable" = "name"))

head(orange)

orange %>%
  ggplot(aes(fill = estimate)) + 
  geom_sf(color = NA) + 
  coord_sf(crs = 26911) + 
  scale_fill_viridis_c(option = "magma") 


zip_county_crosswalk <- read_xlsx("../data/input_data/ZIP_COUNTY_092019.xlsx") %>%
  select(zip, county)

```

Initial Tasks (By end of October)

SEAN WILL WORK ON THIS Generate an exploratory map with CoreLogic percentage underwater data and give to Connie.  

LUCIANA Begin descriptive demographic analysis to describe what high underwater communities have in common and create a memo for Connie. Are there any discernible patterns that bind high underwater and low underwater communities together.  
* Is there a racial disparity? U.S Census data. Percent non-white. 
* Is there an income disparity - median household income -- are these places generally poorer (povery rate) are richer? U.S. Census
* Is there an age difference? Median Age U.S. Census
* Is there a difference in the type and quality of mortgages and loans people have? Not sure where to get this yet.
* Is there an education difference? 
* Is there a difference between housing quality?
* Is there something we can tie it default rates? Or foreclosures? 
* Is it related to the overall performance of the housing market? Did housing get really expensive here? https://www.fhfa.gov/DataTools/Downloads/Pages/House-Price-Index-Datasets.aspx https://www.fhfa.gov/DataTools/Downloads/Documents/HPI/HPI_AT_BDL_ZIP5.xlsx

STEPS
1. Get census data with four columns: five digit zipcode, percent non-white, median household income, poverty rate. 
2. Do an inner join between census data and underwater data
3. Clean it up until we have the columns we want. 
4. Try to figure out if there's a general pattern where highest underwater rates are poorest or non-white majority or lower median household income. 
  - sort and see if the highest underwater rates at top have also lowest or highest demographic features. Or sort by demographics. 
  - filter out just the top 10 and see if there's a pattern there. 
  - the above will be espeically useful in identifying good examples. 
5. Cacluate a statistical measure of the relationship between underwater rates and demographic variables. 
  - Pearson correlation coefficient also known as r.  -1 to 1. With 1 it's a perfect positive correlation or relationship. With -1 it's a perfect negative correlation or relationship and 0 is none. 

## Getting census data

https://data.census.gov/cedsci/
https://factfinder.census.gov/faces/nav/jsf/pages/index.xhtml
The most recent ACS 5-year estimates
https://github.com/walkerke/tidycensus
https://walkerke.github.io/tidycensus/articles/basic-usage.html#searching-for-variables

```{r}
library(tmap)
```

# Maps made in plot mode

```{r}
tmap_mode("plot")
data(World)
tm_shape(World) +
  tm_polygons("HPI")
```
# Maps made in view mode



tmap_mode("view")
data(World)
tm_shape(World) +
  tm_polygons("HPI", id = "iso_a3", popup.vars = TRUE)

```{r}
library(tidycensus)
options(tigris_use_cache = TRUE)
census_api_key("549950d36c22ff16455fe196bbbd01d63cfbe6cf")

orange <- get_acs(geography = "zcta", 
                  variables = "B19013_001", geometry = TRUE)

head(orange)

orange %>%
  ggplot(aes(fill = estimate)) + 
  geom_sf(color = NA) + 
  coord_sf(crs = 26911) + 
  scale_fill_viridis_c(option = "magma") 
```